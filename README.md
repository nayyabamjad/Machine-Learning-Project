# Machine-Learning-Project
This machine learning project utilizes the Iris dataset to compare the performance of two models: Logistic Regression and K-Nearest Neighbors (KNN). The Iris dataset, consisting of 150 samples with four features (sepal length, sepal width, petal length, petal width), is loaded using scikit-learn. The dataset is transformed into a pandas DataFrame, and essential steps such as data exploration, cleaning, and visualization are performed. A scatter matrix is used to visualize the pairwise relationships between features, highlighting three distinct clusters in the dataset.
Data is split into training and test sets to train and evaluate two machine learning models: Logistic Regression and KNN. Logistic Regression, a linear model, predicts the probability of a sample belonging to a class. At the same time, KNN classifies a new data point based on the majority class of its nearest neighbors. The Logistic Regression model is instantiated with 1000 iterations and trained on the data, showing strong performance on the training set but overfitting to some extent.
To further evaluate the KNN model, five variations are generated by adjusting the number of neighbors, ranging from high overfitting to underfitting as the number of neighbors increases. While KNN performs reasonably, the fourth model (with an optimal number of neighbors) performs best among the KNN variations. However, the Logistic Regression model outperforms KNN overall, demonstrating better predictive accuracy and generalization.
This comparative analysis offers valuable insights into the strengths and weaknesses of each model, providing guidance for future machine learning tasks.
